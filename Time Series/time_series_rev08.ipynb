{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.datasets import sunspots\n",
    "\n",
    "def load_dataset(name: str, test_size: float = 0.2, normalize: bool = True):\n",
    "    \"\"\"\n",
    "    Load and preprocess a time series dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - name: Name of the dataset (\"airpassengers\", \"sunspots\", \"electricity\", \"covid\")\n",
    "    - test_size: Fraction of data to be used for testing\n",
    "    - normalize: Whether to normalize the data using MinMaxScaler\n",
    "\n",
    "    Returns:\n",
    "    - train_series: Training part of the series\n",
    "    - test_series: Testing part of the series\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "\n",
    "    if name == \"airpassengers\":\n",
    "        # Simulate monthly passenger numbers with seasonality and trend\n",
    "        np.random.seed(0)\n",
    "        time = np.arange(144)\n",
    "        series = 100 + 10 * np.sin(2 * np.pi * time / 12) + 0.5 * time + np.random.normal(scale=5, size=144)\n",
    "\n",
    "    elif name == \"sunspots\":\n",
    "        df = sunspots.load_pandas().data\n",
    "        series = df['SUNACTIVITY'].values\n",
    "\n",
    "    elif name == \"electricity\":\n",
    "        # Simulated electricity consumption with daily/weekly seasonality\n",
    "        np.random.seed(1)\n",
    "        time = np.arange(1000)\n",
    "        series = 200 + 20 * np.sin(2 * np.pi * time / 24) + 5 * np.sin(2 * np.pi * time / (24*7)) + np.random.normal(scale=10, size=1000)\n",
    "\n",
    "    elif name == \"covid\":\n",
    "        # Simulated COVID-19 daily case counts with waves\n",
    "        np.random.seed(2)\n",
    "        time = np.arange(500)\n",
    "        series = (\n",
    "            1000 * np.exp(-((time - 100) ** 2) / 2000) +\n",
    "            2000 * np.exp(-((time - 300) ** 2) / 3000) +\n",
    "            np.random.normal(scale=50, size=500)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset name: {name}\")\n",
    "\n",
    "    series = series.astype(float).reshape(-1, 1)\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        series = scaler.fit_transform(series).flatten()\n",
    "\n",
    "    train, test = train_test_split(series, test_size=test_size, shuffle=False)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Example test\n",
    "#load_dataset(\"sunspots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model_name: str, train_series, test_steps: int):\n",
    "    \"\"\"\n",
    "    Fit the model and return predictions.\n",
    "    \"\"\"\n",
    "    if model_name == \"ARIMA\":\n",
    "        # Fit ARIMA, return forecast\n",
    "    elif model_name == \"LSTM\":\n",
    "        # Prepare LSTM, return forecast\n",
    "    # ... etc.\n",
    "    return y_pred, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute and return all evaluation metrics.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "    \n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape,\n",
    "        \"sMAPE\": smape\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_all(models, datasets):\n",
    "    \"\"\"\n",
    "    Run all models on all datasets and store results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        train, test = load_dataset(dataset)\n",
    "        for model in models:\n",
    "            try:\n",
    "                y_pred, y_true = train_and_predict(model, train, len(test))\n",
    "                metrics = evaluate_forecast(y_true, y_pred)\n",
    "                results.append({\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Model\": model,\n",
    "                    **metrics\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {model} on {dataset}: {e}\")\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
